{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from xml.etree.ElementTree import iterparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all aws-related question ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_question_id(file):\n",
    "    # get an iterable\n",
    "    context = ET.iterparse(file, events=(\"start\", \"end\"))\n",
    "\n",
    "    is_first = True\n",
    "\n",
    "    question_ids=[]\n",
    "\n",
    "    for event, elem in context:\n",
    "        # get the root element\n",
    "        if is_first:\n",
    "            root = elem\n",
    "            is_first = False\n",
    "        if event == \"end\" and elem.tag == \"row\":\n",
    "            cur_row=elem.attrib\n",
    "            if cur_row['PostTypeId']=='1' and 'Tags' in cur_row:\n",
    "                if 'aws' in cur_row['Tags'] or 'amazon' in cur_row['Tags']:\n",
    "                    question_ids.append(cur_row['Id'])\n",
    "            root.clear()\n",
    "    return question_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_pickle(outfile,question_ids):\n",
    "    with open(outfile, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(question_ids, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pickle(file):\n",
    "    with open(file, \"rb\") as fp:   #Pickling\n",
    "        question_ids = pickle.load(fp)\n",
    "    return question_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_ids=extract_question_id('Posts.xml')\n",
    "write_to_pickle(\"question_ids.txt\",question_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10/15/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Use amazon as keyword for searching AWS related posts. <br>\n",
    "2.Write question information to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def write_question_to_file(infile,outfile)\n",
    "    # get an iterable\n",
    "    context = ET.iterparse(infile, events=(\"start\", \"end\"))\n",
    "    is_first = True\n",
    "    question_list=[]\n",
    "    for event, elem in context:\n",
    "        # get the root element\n",
    "        if is_first:\n",
    "            root = elem\n",
    "            is_first = False\n",
    "        if event == \"end\" and elem.tag == \"row\":\n",
    "            cur_row=elem.attrib\n",
    "            if cur_row['PostTypeId']=='1' and 'Tags' in cur_row:\n",
    "                if 'amazon' in cur_row['Tags']:\n",
    "                    question_list.append(cur_row)\n",
    "            root.clear()\n",
    "            \n",
    "    df=pd.DataFrame(question_list)\n",
    "    df.to_csv(outfile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_question_to_file('Posts.xml','stackoverflow_amazon_q.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10/16/2020\n",
    "\n",
    "1.Write answer information to csv file. (line by line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def write_answer_line_by_line(infile,outfile)\n",
    "    # get an iterable\n",
    "    context = ET.iterparse(infile, events=(\"start\", \"end\"))\n",
    "\n",
    "    is_first = True\n",
    "    example={'Id': '22467', 'PostTypeId': '2', 'ParentId': '22465', 'CreationDate': '2008-08-22T14:20:02.550', 'Score': '0', 'Body': '<p>Seems like dealing with licensing issues would be nightmarish for the host.</p>\\n', 'OwnerUserId': '1902010', 'OwnerDisplayName': 'ceejayoz', 'LastActivityDate': '2008-08-22T14:20:02.550', 'CommentCount': '0', 'ContentLicense': 'CC BY-SA 2.5'}\n",
    "\n",
    "    question_ids=[]\n",
    "    #answer_list=[]\n",
    "\n",
    "\n",
    "    with open(outfile, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        #writer.writerow(example.keys())\n",
    "        for event, elem in context:\n",
    "            # get the root element\n",
    "            if is_first:\n",
    "                root = elem\n",
    "                is_first = False\n",
    "            if event == \"end\" and elem.tag == \"row\":\n",
    "                cur_row=elem.attrib\n",
    "                if cur_row['PostTypeId']=='1' and 'Tags' in cur_row:\n",
    "                    if 'amazon' in cur_row['Tags']:\n",
    "                        question_ids.append(cur_row['Id'])\n",
    "                if cur_row['Id']>'51446634' and cur_row['PostTypeId']=='2' and cur_row['ParentId'] in question_ids:\n",
    "                    writer.writerow(cur_row.values())\n",
    "                    #answer_list.append(cur_row)\n",
    "                root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_answer_line_by_line('Posts.xml','stackoverflow_amazon_a.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10/20/2020\n",
    "1.write outdated answer information to csv (once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV header: ['Id', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "def get_outdated_answer_id_from_csv(infile)\n",
    "\n",
    "    answer_ids=[]\n",
    "\n",
    "    with open(filename, \"r\") as f:  # on Python 3.x use: open(filename, \"r\", newline=\"\")\n",
    "        reader = csv.reader(f)  # create a CSV reader\n",
    "        header = next(reader)  # grab the first line and keep it as a header reference\n",
    "        print(\"CSV header: {}\".format(header))\n",
    "        for row in reader:  # iterate over the available rows\n",
    "            answer_ids.append(row[0]) \n",
    "    return answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_outdated_answer_to_file(infile,outfile,answer_ids):\n",
    "\n",
    "    # get an iterable\n",
    "    context = ET.iterparse(infile, events=(\"start\", \"end\"))\n",
    "\n",
    "    is_first = True\n",
    "\n",
    "\n",
    "    answer_list=[]\n",
    "\n",
    "\n",
    "\n",
    "    for event, elem in context:\n",
    "        # get the root element\n",
    "        if is_first:\n",
    "            root = elem\n",
    "            is_first = False\n",
    "        if event == \"end\" and elem.tag == \"row\":\n",
    "            cur_row=elem.attrib\n",
    "            if cur_row['Id'] in answer_ids:\n",
    "                answer_list.append(cur_row)\n",
    "            root.clear()\n",
    "            \n",
    "    df=pd.DataFrame(answer_list)\n",
    "    df.to_csv(outfile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_ids=get_outdated_answer_id_from_csv(\"outdated_a.csv\")\n",
    "write_outdated_answer_to_file('Posts.xml','stackoverflow_amazon_a_outdated.csv',answer_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
