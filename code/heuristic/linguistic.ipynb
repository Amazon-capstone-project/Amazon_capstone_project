{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.attrs import ORTH, NORM\n",
    "\n",
    "nlp.tokenizer.add_special_case('out of date', [{ORTH:'out of date', NORM: 'outdated'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not outdated.\n",
      "That document get deprecated.\n",
      "It's not discouraged.\n",
      "Service is non-outdated.\n",
      "It's an obsolete document.\n",
      "The article is obsolete.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is not outdated. That document get deprecated. It's not discouraged. \"\n",
    "          \"Service is non-outdated. It's an obsolete document. The article is \"\n",
    "          \"obsolete.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\toutdated\tROOT\tVBN\tVERB\toutdated\t[]\t[is, not, .]\n",
      "8\tdeprecated\tROOT\tJJ\tADJ\tdeprecated\t[]\t[document, get, .]\n",
      "13\tdiscouraged\tROOT\tVBN\tVERB\tdiscouraged\t[]\t[It, 's, not, .]\n",
      "19\toutdated\tacomp\tJJ\tADJ\tis\t[is]\t[-]\n",
      "24\tobsolete\tamod\tJJ\tADJ\tdocument\t[document, 's]\t[]\n",
      "30\tobsolete\tacomp\tJJ\tADJ\tis\t[is]\t[]\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens  import Token\n",
    "from typing import List\n",
    "\n",
    "KEYWORDS = ['outdated', 'discouraged', 'deprecated', 'obsolete']\n",
    "\n",
    "tokens: List[Token] = list(doc)\n",
    "for t in tokens:\n",
    "    if t.text in KEYWORDS:\n",
    "        print(f\"{t.i}\\t{t.text}\\t{t.dep_}\"\n",
    "              f\"\\t{t.tag_}\\t{t.pos_}\\t{t.head}\"\n",
    "              f\"\\t{list(t.ancestors)}\\t{list(t.children)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_outdated = doc[3]\n",
    "t_outdated_children: List[Token] = list(t_outdated.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if child of the keyword contains negation words i.e. 'not'\n",
    "any((child.dep_ == 'neg' for child in t_outdated.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n"
     ]
    }
   ],
   "source": [
    "for t in doc[:5]:\n",
    "    if t.dep_ == 'nsubj':\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_modifier = doc[24]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for tok in doc:\n",
    "    print(\"lemma: {}  \\t dep: {} \\t pos: {} \\t head: {}\".format(tok.lemma_, tok.dep_, tok.pos_, tok.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent.start, sent.end)\n",
    "    print(doc[sent.start], doc[sent.end - 1])\n",
    "    print(sent.end_char)\n",
    "    print(str(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "KEYWORDS = ['outdated']\n",
    "\n",
    "from typing import Optional, Dict, List\n",
    "from spacy.tokens import Doc, Token\n",
    "\n",
    "def analyse_sentence(sentence: spacy.tokens.Span) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Analyse a sentence from a doc.\n",
    "    punct: ? . !\n",
    "    negative statement: not\n",
    "    dep of keyword: ROOT or amod\n",
    "    https://spacy.io/usage/linguistic-features#pos-tagging\n",
    "    \"\"\"\n",
    "    ref_doc: List[Token] = sentence.doc\n",
    "    text = str(sentence)\n",
    "    if any([kw in text for kw in KEYWORDS]) is False:\n",
    "        return None\n",
    "    start, end = sentence.start, sentence.end - 1\n",
    "    # print_tokens(ref_doc[start:end])\n",
    "    punctuation = ref_doc[end]\n",
    "    target = None\n",
    "    negation = False\n",
    "    for token in ref_doc[start:end]:\n",
    "        if token.dep_ == 'neg': negation = True\n",
    "        if token.text not in KEYWORDS: continue\n",
    "        if token.dep_ == 'ROOT':\n",
    "            for child in token.children:\n",
    "                if child.dep_ == 'nsubjpass':\n",
    "                    target = child.text\n",
    "        elif token.dep_ == 'amod':\n",
    "            for child in token.children:\n",
    "                if child.dep_ == 'attr':\n",
    "                    target = child.text\n",
    "        elif token.dep_ == 'acomp': # dep_ can be 'acomp'\n",
    "            for t in ref_doc[start:end]:\n",
    "                if t.dep_ == 'nsubj':\n",
    "                    target = t.text\n",
    "                    break\n",
    "        else:\n",
    "            print(token.doc)\n",
    "            continue\n",
    "    return {\n",
    "        \"modified_noun\": target,\n",
    "        \"punctuation\": punctuation,\n",
    "        \"negative_statement\": negation\n",
    "    }\n",
    "\n",
    "def analyse_content(text: str, nlp) -> Dict:\n",
    "    \"\"\"Analyse a text i.e. the comment.\"\"\"\n",
    "    clean_text = text.replace('out of date', 'outdated')\n",
    "    document: Doc = nlp(clean_text)\n",
    "    res = [analyse_sentence(s) for s in document.sents]\n",
    "    analysis: List[dict] = [r for r in res if r is not None]\n",
    "    neg_cnt = sum([r.get('negative_statement', 0) for r in analysis])\n",
    "    if len(analysis) == 0:\n",
    "        analysis.append(dict())\n",
    "    output = {\n",
    "        \"cnt_keywords\": len(analysis),\n",
    "        \"subject\": analysis[0].get('modified_noun', \"\"),\n",
    "        \"punctuation\": analysis[0].get('punctuation', \"\"),\n",
    "        \"negative_statement\": neg_cnt\n",
    "    }\n",
    "    return output\n",
    "\n",
    "def print_tokens(tokens: List[Token]):\n",
    "    \"\"\"Print a sequence of tokens.\"\"\"\n",
    "    print(\"Idx\\tText\\tdep\\ttag\\tpos\\thead\\tancestor\\tchildren\")\n",
    "    for t in tokens:\n",
    "        print(f\"{t.i}\\t{t.text}\\t{t.dep_}\"\n",
    "              f\"\\t{t.tag_}\\t{t.pos_}\\t{t.head}\"\n",
    "              f\"\\t{list(t.ancestors)}\\t{list(t.children)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Idx\tText\tdep\ttag\tpos\thead\tancestor\tchildren\n0\t\\\tcompound\tNNP\tPROPN\tMD5\t[MD5, is]\t[]\n1\tMD5\tnsubj\tNNP\tPROPN\tis\t[is]\t[\\]\n2\tis\tROOT\tVBZ\tAUX\tis\t[]\t[MD5, function, and]\n3\ta\tdet\tDT\tDET\tfunction\t[function, is]\t[]\n4\tvery\tadvmod\tRB\tADV\tweak\t[weak, function, is]\t[]\n5\tweak\tamod\tJJ\tADJ\tfunction\t[function, is]\t[very]\n6\thash\tcompound\tNN\tNOUN\tfunction\t[function, is]\t[]\n7\tfunction\tattr\tNN\tNOUN\tis\t[is]\t[a, weak, hash]\n8\tand\tcc\tCC\tCCONJ\tis\t[is]\t[]\n9\tit\tnsubj\tPRP\tPRON\t's\t['s, discouraged]\t[]\n10\t's\tnsubjpass\tVBZ\tAUX\tdiscouraged\t[discouraged]\t[it, usage, http://en.wikipedia.org/wiki/MD5]\n11\tusage\tattr\tNN\tNOUN\t's\t['s, discouraged]\t[]\n12\thas\taux\tVBZ\tAUX\tdiscouraged\t[discouraged]\t[]\n13\tbeen\tauxpass\tVBN\tAUX\tdiscouraged\t[discouraged]\t[]\n14\tdiscouraged\tROOT\tVBN\tVERB\tdiscouraged\t[]\t['s, has, been, for, now, :, .]\n15\tfor\tprep\tIN\tADP\tdiscouraged\t[discouraged]\t[years]\n16\tmany\tamod\tJJ\tADJ\tyears\t[years, for, discouraged]\t[]\n17\tyears\tpobj\tNNS\tNOUN\tfor\t[for, discouraged]\t[many]\n18\tnow\tadvmod\tRB\tADV\tdiscouraged\t[discouraged]\t[]\n19\t:\tpunct\t:\tPUNCT\tdiscouraged\t[discouraged]\t[]\n20\thttp://en.wikipedia.org/wiki/MD5\tappos\tADD\tX\t's\t['s, discouraged]\t[]\n21\t.\tpunct\t.\tPUNCT\tdiscouraged\t[discouraged]\t[]\n22\tUse\tROOT\tNNP\tPROPN\tUse\t[]\t[SHA2, nowadays, .]\n23\tSHA2\tdobj\tNNP\tPROPN\tUse\t[Use]\t[]\n24\tnowadays\tadvmod\tRB\tADV\tUse\t[Use]\t[]\n25\t.\tpunct\t.\tPUNCT\tUse\t[Use]\t[]\n26\tMD5\tnsubj\tNN\tNOUN\tis\t[is]\t[]\n27\tis\tROOT\tVBZ\tAUX\tis\t[]\t[MD5, lipstick, .]\n28\tlipstick\tattr\tJJ\tADJ\tis\t[is]\t[on]\n29\ton\tprep\tIN\tADP\tlipstick\t[lipstick, is]\t[pig]\n30\ta\tdet\tDT\tDET\tpig\t[pig, on, lipstick, is]\t[]\n31\tpig\tpobj\tNN\tNOUN\ton\t[on, lipstick, is]\t[a, with]\n32\twith\tprep\tIN\tADP\tpig\t[pig, on, lipstick, is]\t[crisis]\n33\tan\tdet\tDT\tDET\tcrisis\t[crisis, with, pig, on, lipstick, is]\t[]\n34\tidentity\tcompound\tNN\tNOUN\tcrisis\t[crisis, with, pig, on, lipstick, is]\t[]\n35\tcrisis\tpobj\tNN\tNOUN\twith\t[with, pig, on, lipstick, is]\t[an, identity]\n36\t.\tpunct\t.\tPUNCT\tis\t[is]\t[]\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"It is a non-outdated idea. This idea may not be outdated. This idea is never obsolete. Amazon network service is outdated. Actor server is obsolete. Data become outdated, old and obsolete. It is an old and outdated science boook. MD5 is a very weak hash function and it's usage has been discouraged for many years now: http://en.wikipedia.org/wiki/MD5. Use SHA2 nowadays. MD5 is lipstick on a pig with an identity crisis. \")\n",
    "print_tokens(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnt_keywords': 1,\n",
       " 'subject': 'question',\n",
       " 'punctuation': .,\n",
       " 'negative_statement': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = analyse_content(\"This question and answers are out of date now that SimpleDB supports consistent reads and \"\n",
    "                      \"conditional puts. See http://developer.amazonwebservices.com/connect/ann.jspa?annID=611\", nlp)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-DS",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}